{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:SteelBlue\">Module 4:</span> Model Training\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "At last, it's time to build our models!\n",
    "\n",
    "It might seem like it took us a while to get here, but professional data\n",
    "scientists actually spend the bulk of their time on the 3 steps leading\n",
    "up to this one:\n",
    "\n",
    "-   Exploratory Analysis\n",
    "-   Data Cleaning\n",
    "-   Feature Engineering\n",
    "\n",
    "That's because the biggest jumps in model performance are from **better\n",
    "data**, not from fancier algorithms.\n",
    "\n",
    "This is lengthy and action-packed module, so buckle up and let's dive\n",
    "right in!\n",
    "\n",
    "  \n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "### In this module...<a href=\"#In-this-module...\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "First, we'll load our analytical base table from Module 3.\n",
    "\n",
    "Then, we'll go through the essential modeling steps:\n",
    "\n",
    "1.  [Split your dataset](#split)\n",
    "2.  [Build model pipelines](#pipelines)\n",
    "3.  [Declare hyperparameters to tune](#hyperparameters)\n",
    "4.  [Fit and tune models with cross-validation](#fit-tune)\n",
    "5.  [Evaluate metrics and select winner](#evaluate)\n",
    "\n",
    "Finally, we'll save the best model as a project deliverable!\n",
    "\n",
    "  \n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "### First, let's import libraries, recruit models, and load the analytical base table.<a href=\"#First,-let&#39;s-import-libraries,-recruit-models,-and-load-the-analytical-base-table.\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Let's import our libraries and load the dataset. It's good practice to\n",
    "keep all of your library imports at the top of your notebook or program.\n",
    "\n",
    "Before anything else, let's import the `print()` function from the\n",
    "future for compatability with Python 3.\n",
    "\n",
    "In \\[1\\]:\n",
    "\n",
    "    from __future__ import print_function  # Compatability with Python 3\n",
    "    print( 'Print function ready to serve.' )\n",
    "\n",
    "    Print function ready to serve.\n",
    "\n",
    "Next, let's import the libraries we'll need for this module.\n",
    "\n",
    "In \\[2\\]:\n",
    "\n",
    "    # NumPy for numerical computing\n",
    "    import numpy as np\n",
    "\n",
    "    # Pandas for DataFrames\n",
    "    import pandas as pd\n",
    "    pd.set_option('display.max_columns', 100)\n",
    "    pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "    # Matplotlib for visualization\n",
    "    from matplotlib import pyplot as plt\n",
    "    # display plots in the notebook\n",
    "    %matplotlib inline \n",
    "\n",
    "    # Seaborn for easier visualization\n",
    "    import seaborn as sns\n",
    "\n",
    "    # Scikit-Learn for Modeling\n",
    "    import sklearn\n",
    "\n",
    "Next, let's import the 5 algorithms we introduced in Module 4.\n",
    "\n",
    "In \\[3\\]:\n",
    "\n",
    "    # Import Elastic Net, Ridge Regression, and Lasso Regression\n",
    "    from sklearn.linear_model import ElasticNet, Ridge, Lasso\n",
    "\n",
    "    # Import Random Forest and Gradient Boosted Trees\n",
    "    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "**Quick note about this module.**  \n",
    "In this module, we'll be relying heavily on Scikit-Learn, which has many\n",
    "helpful functions we can take advantage of. However, we won't import\n",
    "everything right away. Instead, we'll be importing each function from\n",
    "Scikit-Learn as we need it. That way, we can point out where you can\n",
    "find each function.\n",
    "\n",
    "Next, let's load the analytical base table from Module 3.\n",
    "\n",
    "In \\[4\\]:\n",
    "\n",
    "    # Load cleaned dataset from Module 3\n",
    "    df = pd.read_csv('analytical_base_table.csv')\n",
    "\n",
    "    print(df.shape)\n",
    "\n",
    "    (1863, 40)\n",
    "\n",
    "  \n",
    "\n",
    "# 1. Split your dataset<a href=\"#1.-Split-your-dataset\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Let's start with a crucial but sometimes overlooked step: **Spending**\n",
    "your data.\n",
    "\n",
    "  \n",
    "First, let's import the `train_test_split()` function from Scikit-Learn.\n",
    "\n",
    "In \\[5\\]:\n",
    "\n",
    "    # Function for splitting training and test set\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "Next, separate your dataframe into separate objects for the target\n",
    "variable (`y`) and the input features (`X`).\n",
    "\n",
    "In \\[6\\]:\n",
    "\n",
    "    # Create separate object for target variable\n",
    "    y = df.tx_price\n",
    "\n",
    "    # Create separate object for input features\n",
    "    X = df.drop('tx_price', axis = 1)\n",
    "\n",
    "  \n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## <span style=\"color:RoyalBlue\">Exercise 5.1</span><a href=\"#Exercise-5.1\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "**First, split `X` and `y` into training and test sets using the\n",
    "`train_test_split()` function.**\n",
    "\n",
    "-   **Tip:** Its first two arguments should be X and y.\n",
    "-   **Pass in the argument `test_size=0.2` to set aside 20% of our\n",
    "    observations for the test set.**\n",
    "-   **Pass in `random_state=1234` to set the random state for replicable\n",
    "    results.**\n",
    "-   You can read more about this function in the\n",
    "    [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "\n",
    "The function returns a tuple with 4 elements:\n",
    "`(X_train, X_test, y_train, y_test)`. Remember, you can **unpack** it.\n",
    "We've given you a head-start below with the code to unpack the tuple:\n",
    "\n",
    "In \\[7\\]:\n",
    "\n",
    "    # Split X and y into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2,\\\n",
    "                                                        random_state = 1234)\n",
    "\n",
    "Let's confirm we have the right number of observations in each subset.\n",
    "\n",
    "  \n",
    "**Next, run this code to confirm the size of each subset is correct.**\n",
    "\n",
    "In \\[8\\]:\n",
    "\n",
    "    print( len(X_train), len(X_test), len(y_train), len(y_test) )\n",
    "\n",
    "    1490 373 1490 373\n",
    "\n",
    "### Next, when we train our models, we can fit them on the `X_train` feature values and `y_train` target values.<a href=\"#Next,-when-we-train-our-models,-we-can-fit-them-on-the-X_train-feature-values-and-y_train-target-values.\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### Finally, when we're ready to evaluate our models on our test set, we would use the trained models to predict `X_test` and evaluate the predictions against `y_test`.<a href=\"#Finally,-when-we&#39;re-ready-to-evaluate-our-models-on-our-test-set,-we-would-use-the-trained-models-to-predict-X_test-and-evaluate-the-predictions-against-y_test.\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "  \n",
    "\n",
    "# 2. Build model pipelines<a href=\"#2.-Build-model-pipelines\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In Modules 1, 2, and 3, you explored the dataset, cleaned it, and\n",
    "engineered new features. However, sometimes we'll want to preprocess the\n",
    "training data even more before feeding it into our algorithms.\n",
    "\n",
    "  \n",
    "First, let's show the summary statistics from our training data.\n",
    "\n",
    "In \\[9\\]:\n",
    "\n",
    "    # Summary statistics of X_train\n",
    "    X_train.describe()\n",
    "\n",
    "Out\\[9\\]:\n",
    "\n",
    "|       | beds     | baths    | sqft     | lot_size   | basement | restaurants | groceries | nightlife | cafes    | shopping | arts_entertainment | beauty_spas | active_life | median_age | married  | college_grad | property_tax | insurance | median_school | num_schools | two_and_two | during_recession | property_age | school_score | property_type_Apartment / Condo / Townhouse | property_type_Single-Family | exterior_walls_Brick | exterior_walls_Brick veneer | exterior_walls_Combination | exterior_walls_Metal | exterior_walls_Missing | exterior_walls_Other | exterior_walls_Siding (Alum/Vinyl) | exterior_walls_Wood | roof_Asphalt | roof_Composition Shingle | roof_Missing | roof_Other | roof_Shake Shingle |\n",
    "|-------|----------|----------|----------|------------|----------|-------------|-----------|-----------|----------|----------|--------------------|-------------|-------------|------------|----------|--------------|--------------|-----------|---------------|-------------|-------------|------------------|--------------|--------------|---------------------------------------------|-----------------------------|----------------------|-----------------------------|----------------------------|----------------------|------------------------|----------------------|------------------------------------|---------------------|--------------|--------------------------|--------------|------------|--------------------|\n",
    "| count | 1490.000 | 1490.000 | 1490.000 | 1490.000   | 1490.000 | 1490.000    | 1490.000  | 1490.000  | 1490.000 | 1490.000 | 1490.000           | 1490.000    | 1490.000    | 1490.000   | 1490.000 | 1490.000     | 1490.000     | 1490.000  | 1490.000      | 1490.000    | 1490.000    | 1490.000         | 1490.000     | 1490.000     | 1490.000                                    | 1490.000                    | 1490.000             | 1490.000                    | 1490.000                   | 1490.000             | 1490.000               | 1490.000             | 1490.000                           | 1490.000            | 1490.000     | 1490.000                 | 1490.000     | 1490.000   | 1490.000           |\n",
    "| mean  | 3.434    | 2.579    | 2322.785 | 12746.660  | 0.879    | 39.496      | 4.389     | 5.005     | 5.186    | 39.561   | 3.362              | 22.909      | 15.770      | 38.509     | 69.471   | 65.013       | 464.266      | 139.610   | 6.510         | 2.779       | 0.093       | 0.266            | 24.344       | 17.940       | 0.419                                       | 0.581                       | 0.360                | 0.024                       | 0.059                      | 0.066                | 0.119                  | 0.038                | 0.268                              | 0.066               | 0.073        | 0.644                    | 0.189        | 0.060      | 0.034              |\n",
    "| std   | 1.073    | 0.930    | 1297.102 | 34805.545  | 0.327    | 46.986      | 4.498     | 8.442     | 7.443    | 52.335   | 4.694              | 25.724      | 17.999      | 6.615      | 19.865   | 17.093       | 227.250      | 71.511    | 1.975         | 0.517       | 0.290       | 0.442            | 21.209       | 6.452        | 0.494                                       | 0.494                       | 0.480                | 0.154                       | 0.236                      | 0.248                | 0.324                  | 0.190                | 0.443                              | 0.248               | 0.260        | 0.479                    | 0.392        | 0.238      | 0.180              |\n",
    "| min   | 1.000    | 1.000    | 500.000  | 0.000      | 0.000    | 0.000       | 0.000     | 0.000     | 0.000    | 0.000    | 0.000              | 0.000       | 0.000       | 22.000     | 11.000   | 5.000        | 88.000       | 30.000    | 1.000         | 1.000       | 0.000       | 0.000            | 0.000        | 3.000        | 0.000                                       | 0.000                       | 0.000                | 0.000                       | 0.000                      | 0.000                | 0.000                  | 0.000                | 0.000                              | 0.000               | 0.000        | 0.000                    | 0.000        | 0.000      | 0.000              |\n",
    "| 25%   | 3.000    | 2.000    | 1351.000 | 1542.000   | 1.000    | 6.000       | 1.000     | 0.000     | 0.000    | 6.000    | 0.000              | 4.000       | 4.000       | 33.000     | 59.000   | 53.250       | 321.000      | 94.000    | 5.000         | 3.000       | 0.000       | 0.000            | 6.000        | 12.000       | 0.000                                       | 0.000                       | 0.000                | 0.000                       | 0.000                      | 0.000                | 0.000                  | 0.000                | 0.000                              | 0.000               | 0.000        | 0.000                    | 0.000        | 0.000      | 0.000              |\n",
    "| 50%   | 4.000    | 3.000    | 1913.500 | 6183.000   | 1.000    | 21.000      | 3.000     | 2.000     | 3.000    | 20.000   | 2.000              | 15.000      | 10.000      | 38.000     | 74.000   | 66.000       | 426.000      | 125.000   | 7.000         | 3.000       | 0.000       | 0.000            | 20.000       | 18.000       | 0.000                                       | 1.000                       | 0.000                | 0.000                       | 0.000                      | 0.000                | 0.000                  | 0.000                | 0.000                              | 0.000               | 0.000        | 1.000                    | 0.000        | 0.000      | 0.000              |\n",
    "| 75%   | 4.000    | 3.000    | 3014.750 | 11761.000  | 1.000    | 56.000      | 7.000     | 6.000     | 6.000    | 50.000   | 5.000              | 35.000      | 21.000      | 43.000     | 84.000   | 78.000       | 572.000      | 169.000   | 8.000         | 3.000       | 0.000       | 1.000            | 38.000       | 24.000       | 1.000                                       | 1.000                       | 1.000                | 0.000                       | 0.000                      | 0.000                | 0.000                  | 0.000                | 1.000                              | 0.000               | 0.000        | 1.000                    | 0.000        | 0.000      | 0.000              |\n",
    "| max   | 5.000    | 6.000    | 7842.000 | 436471.000 | 1.000    | 266.000     | 24.000    | 53.000    | 47.000   | 340.000  | 35.000             | 177.000     | 94.000      | 69.000     | 100.000  | 100.000      | 4508.000     | 1374.000  | 10.000        | 4.000       | 1.000       | 1.000            | 114.000      | 30.000       | 1.000                                       | 1.000                       | 1.000                | 1.000                       | 1.000                      | 1.000                | 1.000                  | 1.000                | 1.000                              | 1.000               | 1.000        | 1.000                    | 1.000        | 1.000      | 1.000              |\n",
    "\n",
    "Next, standardize the training data manually, creating a new\n",
    "`X_train_new` object.\n",
    "\n",
    "In \\[10\\]:\n",
    "\n",
    "    # Standardize X_train\n",
    "    X_train_new = (X_train - X_train.mean())/X_train.std()\n",
    "\n",
    "Let's look at the summary statistics for `X_train_new` to confirm\n",
    "standarization worked correctly.\n",
    "\n",
    "-   How can you tell?\n",
    "\n",
    "In \\[11\\]:\n",
    "\n",
    "    # Summary statistics of X_train_new\n",
    "    X_train_new.describe()\n",
    "\n",
    "Out\\[11\\]:\n",
    "\n",
    "|       | beds     | baths    | sqft     | lot_size | basement | restaurants | groceries | nightlife | cafes    | shopping | arts_entertainment | beauty_spas | active_life | median_age | married  | college_grad | property_tax | insurance | median_school | num_schools | two_and_two | during_recession | property_age | school_score | property_type_Apartment / Condo / Townhouse | property_type_Single-Family | exterior_walls_Brick | exterior_walls_Brick veneer | exterior_walls_Combination | exterior_walls_Metal | exterior_walls_Missing | exterior_walls_Other | exterior_walls_Siding (Alum/Vinyl) | exterior_walls_Wood | roof_Asphalt | roof_Composition Shingle | roof_Missing | roof_Other | roof_Shake Shingle |\n",
    "|-------|----------|----------|----------|----------|----------|-------------|-----------|-----------|----------|----------|--------------------|-------------|-------------|------------|----------|--------------|--------------|-----------|---------------|-------------|-------------|------------------|--------------|--------------|---------------------------------------------|-----------------------------|----------------------|-----------------------------|----------------------------|----------------------|------------------------|----------------------|------------------------------------|---------------------|--------------|--------------------------|--------------|------------|--------------------|\n",
    "| count | 1490.000 | 1490.000 | 1490.000 | 1490.000 | 1490.000 | 1490.000    | 1490.000  | 1490.000  | 1490.000 | 1490.000 | 1490.000           | 1490.000    | 1490.000    | 1490.000   | 1490.000 | 1490.000     | 1490.000     | 1490.000  | 1490.000      | 1490.000    | 1490.000    | 1490.000         | 1490.000     | 1490.000     | 1490.000                                    | 1490.000                    | 1490.000             | 1490.000                    | 1490.000                   | 1490.000             | 1490.000               | 1490.000             | 1490.000                           | 1490.000            | 1490.000     | 1490.000                 | 1490.000     | 1490.000   | 1490.000           |\n",
    "| mean  | -0.000   | -0.000   | 0.000    | 0.000    | 0.000    | 0.000       | 0.000     | 0.000     | 0.000    | 0.000    | -0.000             | 0.000       | 0.000       | -0.000     | -0.000   | -0.000       | 0.000        | -0.000    | 0.000         | 0.000       | -0.000      | -0.000           | -0.000       | -0.000       | 0.000                                       | -0.000                      | 0.000                | 0.000                       | 0.000                      | 0.000                | 0.000                  | 0.000                | 0.000                              | -0.000              | -0.000       | -0.000                   | 0.000        | -0.000     | 0.000              |\n",
    "| std   | 1.000    | 1.000    | 1.000    | 1.000    | 1.000    | 1.000       | 1.000     | 1.000     | 1.000    | 1.000    | 1.000              | 1.000       | 1.000       | 1.000      | 1.000    | 1.000        | 1.000        | 1.000     | 1.000         | 1.000       | 1.000       | 1.000            | 1.000        | 1.000        | 1.000                                       | 1.000                       | 1.000                | 1.000                       | 1.000                      | 1.000                | 1.000                  | 1.000                | 1.000                              | 1.000               | 1.000        | 1.000                    | 1.000        | 1.000      | 1.000              |\n",
    "| min   | -2.269   | -1.697   | -1.405   | -0.366   | -2.688   | -0.841      | -0.976    | -0.593    | -0.697   | -0.756   | -0.716             | -0.891      | -0.876      | -2.496     | -2.943   | -3.511       | -1.656       | -1.533    | -2.790        | -3.440      | -0.319      | -0.601           | -1.148       | -2.316       | -0.850                                      | -1.176                      | -0.749               | -0.157                      | -0.250                     | -0.265               | -0.368                 | -0.198               | -0.606                             | -0.265              | -0.281       | -1.343                   | -0.483       | -0.253     | -0.186             |\n",
    "| 25%   | -0.405   | -0.622   | -0.749   | -0.322   | 0.372    | -0.713      | -0.753    | -0.593    | -0.697   | -0.641   | -0.716             | -0.735      | -0.654      | -0.833     | -0.527   | -0.688       | -0.630       | -0.638    | -0.765        | 0.427       | -0.319      | -0.601           | -0.865       | -0.921       | -0.850                                      | -1.176                      | -0.749               | -0.157                      | -0.250                     | -0.265               | -0.368                 | -0.198               | -0.606                             | -0.265              | -0.281       | -1.343                   | -0.483       | -0.253     | -0.186             |\n",
    "| 50%   | 0.527    | 0.452    | -0.316   | -0.189   | 0.372    | -0.394      | -0.309    | -0.356    | -0.294   | -0.374   | -0.290             | -0.307      | -0.321      | -0.077     | 0.228    | 0.058        | -0.168       | -0.204    | 0.248         | 0.427       | -0.319      | -0.601           | -0.205       | 0.009        | -0.850                                      | 0.850                       | -0.749               | -0.157                      | -0.250                     | -0.265               | -0.368                 | -0.198               | -0.606                             | -0.265              | -0.281       | 0.744                    | -0.483       | -0.253     | -0.186             |\n",
    "| 75%   | 0.527    | 0.452    | 0.533    | -0.028   | 0.372    | 0.351       | 0.581     | 0.118     | 0.109    | 0.199    | 0.349              | 0.470       | 0.291       | 0.679      | 0.731    | 0.760        | 0.474        | 0.411     | 0.754         | 0.427       | -0.319      | 1.662            | 0.644        | 0.939        | 1.176                                       | 0.850                       | 1.334                | -0.157                      | -0.250                     | -0.265               | -0.368                 | -0.198               | 1.650                              | -0.265              | -0.281       | 0.744                    | -0.483       | -0.253     | -0.186             |\n",
    "| max   | 1.459    | 3.676    | 4.255    | 12.174   | 0.372    | 4.821       | 4.360     | 5.685     | 5.618    | 5.741    | 6.741              | 5.990       | 4.346       | 4.609      | 1.537    | 2.047        | 17.794       | 17.262    | 1.767         | 2.360       | 3.129       | 1.662            | 4.227        | 1.869        | 1.176                                       | 0.850                       | 1.334                | 6.353                       | 3.990                      | 3.768                | 2.714                  | 5.059                | 1.650                              | 3.768               | 3.558        | 0.744                    | 2.069        | 3.943      | 5.365              |\n",
    "\n",
    "For the most part, we'll almost never perform manual standardization\n",
    "because we'll include preprocessing steps in **model pipelines**.\n",
    "\n",
    "  \n",
    "So let's import the `make_pipeline()` function from Scikit-Learn.\n",
    "\n",
    "In \\[12\\]:\n",
    "\n",
    "    # Function for creating model pipelines\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "\n",
    "Now let's import the `StandardScaler`, which is used for\n",
    "standardization.\n",
    "\n",
    "In \\[13\\]:\n",
    "\n",
    "    # For standardization\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "Next, create a `pipelines` dictionary.\n",
    "\n",
    "-   It should include 3 keys: `'lasso'`, `'ridge'`, and `'enet'`\n",
    "-   The corresponding values should be pipelines that first standardize\n",
    "    the data.\n",
    "-   For the algorithm in each pipeline, set `random_state=123` to ensure\n",
    "    replicable results.\n",
    "\n",
    "In \\[14\\]:\n",
    "\n",
    "    # Create pipelines dictionary\n",
    "    pipelines =  {\n",
    "                'lasso': make_pipeline(StandardScaler(), Lasso(random_state=123)),\n",
    "                'ridge': make_pipeline(StandardScaler(), Ridge(random_state=123)),\n",
    "                'enet': make_pipeline(StandardScaler(), ElasticNet(random_state=123))\n",
    "                    }\n",
    "\n",
    "In the next exercise, you'll add pipelines for tree ensembles.\n",
    "\n",
    "### Exercise 5.2<a href=\"#Exercise-5.2\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### Add pipelines for RandomForestRegressor and GradientBoostingRegressor to your pipeline dictionary.<a href=\"#Add-pipelines-for-RandomForestRegressor-and-GradientBoostingRegressor-to-your-pipeline-dictionary.\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### Name them 'rf' for random forest and 'gb' for gradient boosted tree.<a href=\"#Name-them-&#39;rf&#39;-for-random-forest-and-&#39;gb&#39;-for-gradient-boosted-tree.\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### Both pipelines should standardize the data first.<a href=\"#Both-pipelines-should-standardize-the-data-first.\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### For both, set random_state=123 to ensure replicable results.<a href=\"#For-both,-set-random_state=123-to-ensure-replicable-results.\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[15\\]:\n",
    "\n",
    "    # Add a pipeline for 'rf'\n",
    "    pipelines['rf'] = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=123))\n",
    "\n",
    "    # Add a pipeline for 'gb'\n",
    "    pipelines['gb'] = make_pipeline(StandardScaler(),\n",
    "                                    GradientBoostingRegressor(random_state=123 ))\n",
    "\n",
    "Let's make sure our dictionary has pipelines for each of our algorithms.\n",
    "\n",
    "  \n",
    "**Run this code to confirm that you have all 5 algorithms, each part of\n",
    "a pipeline.**\n",
    "\n",
    "In \\[16\\]:\n",
    "\n",
    "    # Check that we have all 5 algorithms, and that they are all pipelines\n",
    "    for key, value in pipelines.items():\n",
    "        print( key, type(value) )\n",
    "\n",
    "    enet <class 'sklearn.pipeline.Pipeline'>\n",
    "    gb <class 'sklearn.pipeline.Pipeline'>\n",
    "    ridge <class 'sklearn.pipeline.Pipeline'>\n",
    "    rf <class 'sklearn.pipeline.Pipeline'>\n",
    "    lasso <class 'sklearn.pipeline.Pipeline'>\n",
    "\n",
    "### Now that we have our pipelines, we're ready to move on to declaring hyperparameters to tune.<a href=\"#Now-that-we-have-our-pipelines,-we&#39;re-ready-to-move-on-to-declaring-hyperparameters-to-tune.\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "  \n",
    "\n",
    "# 3. Declare hyperparameters to tune<a href=\"#3.-Declare-hyperparameters-to-tune\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Up to now, we've been casually talking about \"tuning\" models, but now\n",
    "it's time to treat the topic more formally.\n",
    "\n",
    "  \n",
    "First, list all the tunable hyperparameters for your Lasso regression\n",
    "pipeline.\n",
    "\n",
    "In \\[17\\]:\n",
    "\n",
    "    # List tuneable hyperparameters of our Lasso pipeline\n",
    "    pipelines['lasso'].get_params()\n",
    "\n",
    "Out\\[17\\]:\n",
    "\n",
    "    {'lasso': Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "        normalize=False, positive=False, precompute=False, random_state=123,\n",
    "        selection='cyclic', tol=0.0001, warm_start=False),\n",
    "     'lasso__alpha': 1.0,\n",
    "     'lasso__copy_X': True,\n",
    "     'lasso__fit_intercept': True,\n",
    "     'lasso__max_iter': 1000,\n",
    "     'lasso__normalize': False,\n",
    "     'lasso__positive': False,\n",
    "     'lasso__precompute': False,\n",
    "     'lasso__random_state': 123,\n",
    "     'lasso__selection': 'cyclic',\n",
    "     'lasso__tol': 0.0001,\n",
    "     'lasso__warm_start': False,\n",
    "     'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
    "     'standardscaler__copy': True,\n",
    "     'standardscaler__with_mean': True,\n",
    "     'standardscaler__with_std': True,\n",
    "     'steps': [('standardscaler',\n",
    "       StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
    "      ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "          normalize=False, positive=False, precompute=False, random_state=123,\n",
    "          selection='cyclic', tol=0.0001, warm_start=False))]}\n",
    "\n",
    "In \\[17\\]:\n",
    "\n",
    "    # List tuneable hyperparameters of our Lasso pipeline\n",
    "    pipelines['lasso'].get_params()\n",
    "\n",
    "Out\\[17\\]:\n",
    "\n",
    "    {'memory': None,\n",
    "     'steps': [('standardscaler', StandardScaler()),\n",
    "      ('lasso', Lasso(random_state=123))],\n",
    "     'verbose': False,\n",
    "     'standardscaler': StandardScaler(),\n",
    "     'lasso': Lasso(random_state=123),\n",
    "     'standardscaler__copy': True,\n",
    "     'standardscaler__with_mean': True,\n",
    "     'standardscaler__with_std': True,\n",
    "     'lasso__alpha': 1.0,\n",
    "     'lasso__copy_X': True,\n",
    "     'lasso__fit_intercept': True,\n",
    "     'lasso__max_iter': 1000,\n",
    "     'lasso__positive': False,\n",
    "     'lasso__precompute': False,\n",
    "     'lasso__random_state': 123,\n",
    "     'lasso__selection': 'cyclic',\n",
    "     'lasso__tol': 0.0001,\n",
    "     'lasso__warm_start': False}\n",
    "\n",
    "Next, declare hyperparameters to tune for Lasso and Ridge regression.\n",
    "\n",
    "-   Try values between 0.001 and 10 for `alpha`.\n",
    "\n",
    "In \\[18\\]:\n",
    "\n",
    "    # Lasso hyperparameters\n",
    "    lasso_hyperparameters = {'lasso__alpha':[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10] }\n",
    "\n",
    "    # Ridge hyperparameters\n",
    "    ridge_hyperparameters = {'ridge__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10] }\n",
    "\n",
    "Now declare a hyperparameter grid fo Elastic-Net.\n",
    "\n",
    "-   You should tune the `l1_ratio` in addition to `alpha`.\n",
    "\n",
    "In \\[19\\]:\n",
    "\n",
    "    # Elastic Net hyperparameters\n",
    "    enet_hyperparameters = {\n",
    "        'elasticnet__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n",
    "        'elasticnet__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    }\n",
    "\n",
    "  \n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## <span style=\"color:RoyalBlue\">Exercise 5.3</span><a href=\"#Exercise-5.3\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Let's start by declaring the hyperparameter grid for our random forest.\n",
    "\n",
    "  \n",
    "**Declare a hyperparameter grid for `RandomForestRegressor`.**\n",
    "\n",
    "-   Name it `rf_hyperparameters`\n",
    "\n",
    "-   Set `'randomforestregressor\\__n_estimators': [100, 200]`\n",
    "\n",
    "-   Set `'randomforestregressor\\__max_features': ['auto', 'sqrt', 0.33]`\n",
    "\n",
    "In \\[20\\]:\n",
    "\n",
    "    # Random forest hyperparameters\n",
    "    rf_hyperparameters  = {\n",
    "        'randomforestregressor__n_estimators': [100,200],\n",
    "        'randomforestregressor__max_features': ['auto', 'sqrt', 0.33]\n",
    "    }\n",
    "\n",
    "Next, let's declare settings to try for our boosted tree.\n",
    "\n",
    "  \n",
    "**Declare a hyperparameter grid for `GradientBoostingRegressor`.**\n",
    "\n",
    "-   Name it `gb_hyperparameters`.\n",
    "-   Set `'gradientboostingregressor\\__n_estimators': [100, 200]`\n",
    "-   Set `'gradientboostingregressor\\__learning_rate': [0.05, 0.1, 0.2]`\n",
    "-   Set `'gradientboostingregressor\\__max_depth': [1, 3, 5]`\n",
    "\n",
    "In \\[21\\]:\n",
    "\n",
    "    # Boosted tree hyperparameters\n",
    "    gb_hyperparameters = {\n",
    "                'gradientboostingregressor__n_estimators' : [100,200],\n",
    "                'gradientboostingregressor__learning_rate': [0.05, 0.1,0.2],\n",
    "                'gradientboostingregressor__max_depth': [1,3,5]\n",
    "    }\n",
    "\n",
    "Now that we have all of our hyperparameters declared, let's store them\n",
    "in a dictionary for ease of access.\n",
    "\n",
    "  \n",
    "**Create a `hyperparameters` dictionary**.\n",
    "\n",
    "-   Use the same keys as in the `pipelines` dictionary.\n",
    "    -   If you forgot what those keys were, you can insert a new code\n",
    "        cell and call `pipelines.keys()` for a reminder.\n",
    "-   Set the values to the corresponding **hyperparameter grids** we've\n",
    "    been declaring throughout this module.\n",
    "    -   e.g. `'rf' : rf_hyperparameters`\n",
    "    -   e.g. `'lasso' : lasso_hyperparameters`\n",
    "\n",
    "In \\[22\\]:\n",
    "\n",
    "    # Create hyperparameters dictionary\n",
    "    hyperparameters = {\n",
    "        'rf': rf_hyperparameters,\n",
    "        'gb': gb_hyperparameters,\n",
    "        'lasso': lasso_hyperparameters,\n",
    "        'ridge': ridge_hyperparameters,\n",
    "        'enet': enet_hyperparameters\n",
    "    }\n",
    "\n",
    "**Finally, run this code to check that `hyperparameters` is set up\n",
    "correctly.**\n",
    "\n",
    "In \\[23\\]:\n",
    "\n",
    "    for key in ['enet', 'gb', 'ridge', 'rf', 'lasso']:\n",
    "        if key in hyperparameters:\n",
    "            if type(hyperparameters[key]) is dict:\n",
    "                print( key, 'was found in hyperparameters, and it is a grid.' )\n",
    "            else:\n",
    "                print( key, 'was found in hyperparameters, but it is not a grid.' )\n",
    "        else:\n",
    "            print( key, 'was not found in hyperparameters')\n",
    "\n",
    "    enet was found in hyperparameters, and it is a grid.\n",
    "    gb was found in hyperparameters, and it is a grid.\n",
    "    ridge was found in hyperparameters, and it is a grid.\n",
    "    rf was found in hyperparameters, and it is a grid.\n",
    "    lasso was found in hyperparameters, and it is a grid.\n",
    "\n",
    "  \n",
    "\n",
    "# 4. Fit and tune models with cross-validation<a href=\"#4.-Fit-and-tune-models-with-cross-validation\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Now that we have our `pipelines` and `hyperparameters` dictionaries\n",
    "declared, we're ready to tune our models with cross-validation.\n",
    "\n",
    "  \n",
    "First, let's to import a helper for cross-validation called\n",
    "`GridSearchCV`.\n",
    "\n",
    "In \\[24\\]:\n",
    "\n",
    "    # Helper for cross-validation\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "Next, to see an example, set up cross-validation for Lasso regression.\n",
    "\n",
    "In \\[25\\]:\n",
    "\n",
    "    # Create cross-validation object from Lasso pipeline and Lasso hyperparameters\n",
    "    model = GridSearchCV(pipelines['lasso'], hyperparameters['lasso'], cv=10, n_jobs=-1)\n",
    "\n",
    "Pass `X_train` and `y_train` into the `.fit()` function to tune\n",
    "hyperparameters.\n",
    "\n",
    "In \\[26\\]:\n",
    "\n",
    "    # Fit and tune model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "Out\\[26\\]:\n",
    "\n",
    "    GridSearchCV(cv=10,\n",
    "                 estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "                                           ('lasso', Lasso(random_state=123))]),\n",
    "                 n_jobs=-1,\n",
    "                 param_grid={'lasso__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1,\n",
    "                                              5, 10]})\n",
    "\n",
    "**In a Jupyter environment, please rerun this cell to show the HTML\n",
    "representation or trust the notebook.  \n",
    "On GitHub, the HTML representation is unable to render, please try\n",
    "loading this page with nbviewer.org.**\n",
    "\n",
    "  GridSearchCV<a href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\" class=\"sk-estimator-doc-link fitted\">?<span>Documentation for GridSearchCV</span></a><span\n",
    "class=\"sk-estimator-doc-link fitted\">iFitted</span>\n",
    "\n",
    "    GridSearchCV(cv=10,\n",
    "                 estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "                                           ('lasso', Lasso(random_state=123))]),\n",
    "                 n_jobs=-1,\n",
    "                 param_grid={'lasso__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1,\n",
    "                                              5, 10]})\n",
    "\n",
    "estimator: Pipeline\n",
    "\n",
    "    Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "                    ('lasso', Lasso(random_state=123))])\n",
    "\n",
    " StandardScaler<a href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\" class=\"sk-estimator-doc-link fitted\">?<span>Documentation for StandardScaler</span></a>\n",
    "\n",
    "    StandardScaler()\n",
    "\n",
    " Lasso<a href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.Lasso.html\" class=\"sk-estimator-doc-link fitted\">?<span>Documentation for Lasso</span></a>\n",
    "\n",
    "    Lasso(random_state=123)\n",
    "\n",
    "### In the next exercise, we'll write a loop that tunes all of our models.<a href=\"#In-the-next-exercise,-we&#39;ll-write-a-loop-that-tunes-all-of-our-models.\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "  \n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## <span style=\"color:RoyalBlue\">Exercise 5.4</span><a href=\"#Exercise-5.4\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "**Create a dictionary of models named `fitted_models` that have been\n",
    "tuned using cross-validation.**\n",
    "\n",
    "-   The keys should be the same as those in the `pipelines` and\n",
    "    `hyperparameters` dictionaries.\n",
    "-   The values should be `GridSearchCV` objects that have been fitted to\n",
    "    `X_train` and `y_train`.\n",
    "-   After fitting each model, print `'{name} has been fitted.'` just to\n",
    "    track the progress.\n",
    "-   **Tip:** We've started you off with some code.\n",
    "\n",
    "This step can take a few minutes, so please be patient.\n",
    "\n",
    "In \\[28\\]:\n",
    "\n",
    "    # Create empty dictionary called fitted_models\n",
    "    fitted_models = {}\n",
    "\n",
    "    # Loop through model pipelines, tuning each one and saving it to fitted_models\n",
    "    for name, pipeline in pipelines.items():\n",
    "        # Create cross-validation object from pipeline and hyperparameters\n",
    "        model = GridSearchCV(pipeline, hyperparameters[name], cv = 10, n_jobs=-1)\n",
    "        \n",
    "        # Fit model on X_train, y_train\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Store model in fitted_models[name] \n",
    "        fitted_models[name] = model\n",
    "        \n",
    "        # Print '{name} has been fitted'\n",
    "        print(name, 'has been fitted.')\n",
    "\n",
    "    lasso has been fitted.\n",
    "    ridge has been fitted.\n",
    "    enet has been fitted.\n",
    "\n",
    "    C:\\Users\\Amrendra Mishra\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
    "    20 fits failed out of a total of 60.\n",
    "    The score on these train-test partitions for these parameters will be set to nan.\n",
    "    If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
    "\n",
    "    Below are more details about the failures:\n",
    "    --------------------------------------------------------------------------------\n",
    "    7 fits failed with the following error:\n",
    "    Traceback (most recent call last):\n",
    "      File \"C:\\Users\\Amrendra Mishra\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
    "        estimator.fit(X_train, y_train, **fit_params)\n",
    "      File \"C:\\Users\\Amrendra Mishra\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
    "        return fit_method(estimator, *args, **kwargs)\n",
    "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "      File \"C:\\Users\\Amrendra Mishra\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
    "        self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
    "      File \"C:\\Users\\Amrendra Mishra\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
    "        estimator._validate_params()\n",
    "      File \"C:\\Users\\Amrendra Mishra\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
    "        validate_parameter_constraints(\n",
    "      File \"C:\\Users\\Amrendra Mishra\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
    "        raise InvalidParameterError(\n",
    "    sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
    "\n",
    "    --------------------------------------------------------------------------------\n",
    "    13 fits failed with the following error:\n",
    "    Traceback (most recent call last):\n",
    "      File \"C:\\Users\\Amrendra Mishra\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
    "        estimator.fit(X_train, y_train, **fit_params)\n",
    "      File \"C:\\Users\\Amrendra Mishra\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
    "        return fit_method(estimator, *args, **kwargs)\n",
    "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "      File \"C:\\Users\\Amrendra Mishra\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
    "        self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
    "      File \"C:\\Users\\Amrendra Mishra\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
    "        estimator._validate_params()\n",
    "      File \"C:\\Users\\Amrendra Mishra\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
    "        validate_parameter_constraints(\n",
    "      File \"C:\\Users\\Amrendra Mishra\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
    "        raise InvalidParameterError(\n",
    "    sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
    "\n",
    "      warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
    "    C:\\Users\\Amrendra Mishra\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.46190669 0.46536719 0.47041944 0.4732383 ]\n",
    "      warnings.warn(\n",
    "\n",
    "    rf has been fitted.\n",
    "    gb has been fitted.\n",
    "\n",
    "  \n",
    "**Run this code to check that the models are of the correct type.**\n",
    "\n",
    "In \\[28\\]:\n",
    "\n",
    "    # Check that we have 5 cross-validation objects\n",
    "    for key, value in fitted_models.items():\n",
    "        print( key, type(value) )\n",
    "\n",
    "    enet <class 'sklearn.model_selection._search.GridSearchCV'>\n",
    "    lasso <class 'sklearn.model_selection._search.GridSearchCV'>\n",
    "    ridge <class 'sklearn.model_selection._search.GridSearchCV'>\n",
    "    gb <class 'sklearn.model_selection._search.GridSearchCV'>\n",
    "    rf <class 'sklearn.model_selection._search.GridSearchCV'>\n",
    "\n",
    "  \n",
    "**Finally, run this code to check that the models have been fitted\n",
    "correctly.**\n",
    "\n",
    "In \\[29\\]:\n",
    "\n",
    "    from sklearn.exceptions import NotFittedError\n",
    "\n",
    "    for name, model in fitted_models.items():\n",
    "        try:\n",
    "            pred = model.predict(X_test)\n",
    "            print(name, 'has been fitted.')\n",
    "        except NotFittedError as e:\n",
    "            print(repr(e))\n",
    "\n",
    "    enet has been fitted.\n",
    "    lasso has been fitted.\n",
    "    ridge has been fitted.\n",
    "    gb has been fitted.\n",
    "    rf has been fitted.\n",
    "\n",
    "### Nice. Now we're ready to evaluate how our models performed!<a href=\"#Nice.-Now-we&#39;re-ready-to-evaluate-how-our-models-performed!\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "  \n",
    "\n",
    "# 5. Evaluate models and select winner<a href=\"#5.-Evaluate-models-and-select-winner\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Finally, it's time to evaluate our models and pick the best one.\n",
    "\n",
    "  \n",
    "Let's display the holdout \\$R^2\\$ score for each fitted model.\n",
    "\n",
    "In \\[30\\]:\n",
    "\n",
    "    # Display best_score_ for each fitted model\n",
    "    for name, model in fitted_models.items():\n",
    "        print(name, model.best_score_)\n",
    "\n",
    "    enet 0.342874628832\n",
    "    lasso 0.308627513964\n",
    "    ridge 0.316611158599\n",
    "    gb 0.487628692035\n",
    "    rf 0.480582600666\n",
    "\n",
    "Here's what you should see:\n",
    "\n",
    "    enet 0.342759786956\n",
    "    lasso 0.309321321129\n",
    "    ridge 0.316805719351\n",
    "    gb 0.48873808731\n",
    "    rf 0.480576134721\n",
    "\n",
    "If you get different numbers, check to see if you've set the\n",
    "`random_state=` correctly for each of the models.\n",
    "\n",
    "Next, import the `r2_score()` and `mean_absolute_error()` functions.\n",
    "\n",
    "In \\[31\\]:\n",
    "\n",
    "    # Import r2_score and mean_absolute_error functions\n",
    "    from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "Finally, let's see how the fitted models perform on our test set!\n",
    "\n",
    "  \n",
    "First, access your fitted random forest and display the object.\n",
    "\n",
    "In \\[32\\]:\n",
    "\n",
    "    # Display fitted random forest object\n",
    "    fitted_models['rf']\n",
    "\n",
    "Out\\[32\\]:\n",
    "\n",
    "    GridSearchCV(cv=10, error_score='raise',\n",
    "           estimator=Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "               max_features='auto', max_leaf_nodes=None,\n",
    "               min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "               min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "               n_estimators=10, n_jobs=1, oob_score=False, random_state=123,\n",
    "               verbose=0, warm_start=False))]),\n",
    "           fit_params={}, iid=True, n_jobs=-1,\n",
    "           param_grid={'randomforestregressor__n_estimators': [100, 200], 'randomforestregressor__max_features': ['auto', 'sqrt', 0.33]},\n",
    "           pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
    "           scoring=None, verbose=0)\n",
    "\n",
    "In \\[33\\]:\n",
    "\n",
    "    # Display fitted random forest object\n",
    "    fitted_models['rf']\n",
    "\n",
    "Out\\[33\\]:\n",
    "\n",
    "    GridSearchCV(cv=10,\n",
    "                 estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "                                           ('randomforestregressor',\n",
    "                                            RandomForestRegressor(random_state=123))]),\n",
    "                 n_jobs=-1,\n",
    "                 param_grid={'randomforestregressor__max_features': ['auto', 'sqrt',\n",
    "                                                                     0.33],\n",
    "                             'randomforestregressor__n_estimators': [100, 200]})\n",
    "\n",
    "**In a Jupyter environment, please rerun this cell to show the HTML\n",
    "representation or trust the notebook.  \n",
    "On GitHub, the HTML representation is unable to render, please try\n",
    "loading this page with nbviewer.org.**\n",
    "\n",
    "  GridSearchCV<a href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\" class=\"sk-estimator-doc-link fitted\">?<span>Documentation for GridSearchCV</span></a><span\n",
    "class=\"sk-estimator-doc-link fitted\">iFitted</span>\n",
    "\n",
    "    GridSearchCV(cv=10,\n",
    "                 estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "                                           ('randomforestregressor',\n",
    "                                            RandomForestRegressor(random_state=123))]),\n",
    "                 n_jobs=-1,\n",
    "                 param_grid={'randomforestregressor__max_features': ['auto', 'sqrt',\n",
    "                                                                     0.33],\n",
    "                             'randomforestregressor__n_estimators': [100, 200]})\n",
    "\n",
    "estimator: Pipeline\n",
    "\n",
    "    Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "                    ('randomforestregressor',\n",
    "                     RandomForestRegressor(random_state=123))])\n",
    "\n",
    " StandardScaler<a href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\" class=\"sk-estimator-doc-link fitted\">?<span>Documentation for StandardScaler</span></a>\n",
    "\n",
    "    StandardScaler()\n",
    "\n",
    " RandomForestRegressor<a href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestRegressor.html\" class=\"sk-estimator-doc-link fitted\">?<span>Documentation for RandomForestRegressor</span></a>\n",
    "\n",
    "    RandomForestRegressor(random_state=123)\n",
    "\n",
    "Predict the test set using the fitted random forest.\n",
    "\n",
    "In \\[33\\]:\n",
    "\n",
    "    # Predict test set using fitted random forest\n",
    "    pred = fitted_models['rf'].predict(X_test)\n",
    "\n",
    "Finally, we use the scoring functions we imported to calculate and print\n",
    "\\$R^2\\$ and MAE.\n",
    "\n",
    "In \\[34\\]:\n",
    "\n",
    "    # Calculate and print R^2 and MAE\n",
    "    print('R^2:', r2_score(y_test, pred))\n",
    "    print('MAE: ', mean_absolute_error(y_test, pred))\n",
    "\n",
    "    R^2: 0.568823949153\n",
    "    MAE:  68303.5899464\n",
    "\n",
    "In the next exercise, we'll evaluate all of our fitted models on the\n",
    "test set and pick the winner.\n",
    "\n",
    "  \n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## <span style=\"color:RoyalBlue\">Exercise 5.5</span><a href=\"#Exercise-5.5\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "**Use a `for` loop, print the performance of each model in\n",
    "`fitted_models` on the test set.**\n",
    "\n",
    "-   Print both `r2_score` and `mean_absolute_error`.\n",
    "-   Those functions each take two arguments:\n",
    "    -   The actual values for your target variable (`y_test`)\n",
    "    -   Predicted values for your target variable\n",
    "-   Label the output with the name of the algorithm. For example:\n",
    "\n",
    "```\n",
    "lasso\n",
    "--------\n",
    "R^2: 0.409313458932\n",
    "MAE: 84963.5598922\n",
    "```\n",
    "\n",
    "In \\[35\\]:\n",
    "\n",
    "    # Code here\n",
    "    for name, model in fitted_models.items():\n",
    "        print(name)\n",
    "        print('--------')\n",
    "        pred = model.predict(X_test)\n",
    "        print('R^2:', r2_score(y_test, pred))\n",
    "        print('MAE: ', mean_absolute_error(y_test, pred))\n",
    "        print('\\n')\n",
    "\n",
    "    enet\n",
    "    --------\n",
    "    R^2: 0.405245137477\n",
    "    MAE:  86298.6372415\n",
    "\n",
    "\n",
    "    lasso\n",
    "    --------\n",
    "    R^2: 0.408886246944\n",
    "    MAE:  85035.5424992\n",
    "\n",
    "\n",
    "    ridge\n",
    "    --------\n",
    "    R^2: 0.409339647633\n",
    "    MAE:  84978.0356481\n",
    "\n",
    "\n",
    "    gb\n",
    "    --------\n",
    "    R^2: 0.539882861303\n",
    "    MAE:  70612.6756278\n",
    "\n",
    "\n",
    "    rf\n",
    "    --------\n",
    "    R^2: 0.568823949153\n",
    "    MAE:  68303.5899464\n",
    "\n",
    "**Next, ask yourself these questions to pick the winning model:**\n",
    "\n",
    "-   Which model had the highest \\$R^2\\$ on the test set?\n",
    "\n",
    "> Random forest\n",
    "\n",
    "-   Which model had the lowest mean absolute error?\n",
    "\n",
    "> Random forest\n",
    "\n",
    "-   Are these two models the same one?\n",
    "\n",
    "> Yes\n",
    "\n",
    "-   Did it also have the best holdout \\$R^2\\$ score from\n",
    "    cross-validation?\n",
    "\n",
    "> Yes\n",
    "\n",
    "-   **Does it satisfy our win condition?**\n",
    "\n",
    "> Yes, its mean absolute error is less than \\\\\\$70,000!\n",
    "\n",
    "**Finally, let's plot the performance of the winning model on the test\n",
    "set. Run the code below.**\n",
    "\n",
    "-   It first plots a scatter plot.\n",
    "-   Then, it plots predicted transaction price on the X-axis.\n",
    "-   Finally, it plots actual transaction price on the y-axis.\n",
    "\n",
    "In \\[36\\]:\n",
    "\n",
    "    rf_pred = fitted_models['rf'].predict(X_test)\n",
    "    plt.scatter(rf_pred, y_test)\n",
    "    plt.xlabel('predicted')\n",
    "    plt.ylabel('actual')\n",
    "    plt.show()\n",
    "\n",
    "![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgMAAAFYCAYAAADOev/+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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%0AABERkY9jMEBEROTj/h/Cs1Sg9YQ7ugAAAABJRU5ErkJggg==%0A)\n",
    "\n",
    "### This last visual check is a nice way to confirm our model's performance.<a href=\"#This-last-visual-check-is-a-nice-way-to-confirm-our-model&#39;s-performance.\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### \\* Are the points scattered around the 45 degree diagonal?<a href=\"#*-Are-the-points-scattered-around-the-45-degree-diagonal?\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "  \n",
    "\n",
    "### Finally, let's save the winning model.<a href=\"#Finally,-let&#39;s-save-the-winning-model.\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Great job! You've created a pretty kick-ass model for real-estate\n",
    "valuation. Now it's time to save your hard work.\n",
    "\n",
    "First, let's take a look at the data type of your winning model.\n",
    "\n",
    "In \\[38\\]:\n",
    "\n",
    "    type(fitted_models['rf'])\n",
    "\n",
    "Out\\[38\\]:\n",
    "\n",
    "    sklearn.model_selection._search.GridSearchCV\n",
    "\n",
    "It looks like this is still the `GridSearchCV` data type.\n",
    "\n",
    "-   You can actually directly save this object if you want, because it\n",
    "    will use the winning model pipeline by default.\n",
    "-   However, what we really care about is the actual winning model\n",
    "    `Pipeline`, right?\n",
    "\n",
    "In that case, we can use the `best\\_estimator_` method to access it:\n",
    "\n",
    "In \\[39\\]:\n",
    "\n",
    "    type(fitted_models['rf'].best_estimator_)\n",
    "\n",
    "Out\\[39\\]:\n",
    "\n",
    "    sklearn.pipeline.Pipeline\n",
    "\n",
    "If we output that object directly, we can also see the winning values\n",
    "for our hyperparameters.\n",
    "\n",
    "In \\[40\\]:\n",
    "\n",
    "    fitted_models['rf'].best_estimator_\n",
    "\n",
    "Out\\[40\\]:\n",
    "\n",
    "    Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "               max_features='auto', max_leaf_nodes=None,\n",
    "               min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "               min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "               n_estimators=200, n_jobs=1, oob_score=False, random_state=123,\n",
    "               verbose=0, warm_start=False))])\n",
    "\n",
    "In \\[40\\]:\n",
    "\n",
    "    fitted_models['rf'].best_estimator_\n",
    "\n",
    "Out\\[40\\]:\n",
    "\n",
    "    Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "                    ('randomforestregressor',\n",
    "                     RandomForestRegressor(max_features=0.33, n_estimators=200,\n",
    "                                           random_state=123))])\n",
    "\n",
    "**In a Jupyter environment, please rerun this cell to show the HTML\n",
    "representation or trust the notebook.  \n",
    "On GitHub, the HTML representation is unable to render, please try\n",
    "loading this page with nbviewer.org.**\n",
    "\n",
    "  Pipeline<a href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\" class=\"sk-estimator-doc-link fitted\">?<span>Documentation for Pipeline</span></a><span\n",
    "class=\"sk-estimator-doc-link fitted\">iFitted</span>\n",
    "\n",
    "    Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "                    ('randomforestregressor',\n",
    "                     RandomForestRegressor(max_features=0.33, n_estimators=200,\n",
    "                                           random_state=123))])\n",
    "\n",
    " StandardScaler<a href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\" class=\"sk-estimator-doc-link fitted\">?<span>Documentation for StandardScaler</span></a>\n",
    "\n",
    "    StandardScaler()\n",
    "\n",
    " RandomForestRegressor<a href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestRegressor.html\" class=\"sk-estimator-doc-link fitted\">?<span>Documentation for RandomForestRegressor</span></a>\n",
    "\n",
    "    RandomForestRegressor(max_features=0.33, n_estimators=200, random_state=123)\n",
    "\n",
    "### The winning values for our hyperparameters are:<a href=\"#The-winning-values-for-our-hyperparameters-are:\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "-   `n_estimators: 200`\n",
    "-   `max_features : 'auto'`\n",
    "\n",
    "### Great, now let's import a helpful package called `pickle`, which saves Python objects to disk.<a href=\"#Great,-now-let&#39;s-import-a-helpful-package-called-pickle,-which-saves-Python-objects-to-disk.\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[41\\]:\n",
    "\n",
    "    import pickle\n",
    "\n",
    "Let's save the winning `Pipeline` object into a pickle file.\n",
    "\n",
    "In \\[42\\]:\n",
    "\n",
    "    with open('final_model.pkl', 'wb') as f:\n",
    "        pickle.dump(fitted_models['rf'].best_estimator_, f)\n",
    "\n",
    "### As a reminder, here are a few things you did in this module:<a href=\"#As-a-reminder,-here-are-a-few-things-you-did-in-this-module:\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### You split your dataset into separate training and test sets.<a href=\"#You-split-your-dataset-into-separate-training-and-test-sets.\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### You set up preprocessing pipelines.<a href=\"#You-set-up-preprocessing-pipelines.\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### You tuned your models using cross-validation.<a href=\"#You-tuned-your-models-using-cross-validation.\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### And you evaluated your models, selecting and saving the winner.<a href=\"#And-you-evaluated-your-models,-selecting-and-saving-the-winner.\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "     \n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "     \n",
    "\n",
    "In \\[ \\]:"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
